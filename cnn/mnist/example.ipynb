{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: (70000, 1, 28, 28) labels: (70000, 10)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.datasets        import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing   import label_binarize\n",
    "\n",
    "PIXEL_RANGE = range(0, 255 + 1)\n",
    "IMAGE_RANGE = range(0, 9 + 1)\n",
    "\n",
    "def process(mnist):\n",
    "    # Process dataset to return features and labels for CNN\n",
    "    def features():\n",
    "        # Transform features to be float32 sets of 1x28x28 \n",
    "        # tensors with normalized pixel values.\n",
    "        return np.divide(\n",
    "            mnist.data, PIXEL_RANGE[-1]\n",
    "        ).astype(np.float32).reshape((-1, 1, 28, 28))\n",
    "    def labels():\n",
    "        # Transform labels to be float32 sets of 1x10\n",
    "        # tensors that are one-hot encoded.\n",
    "        return label_binarize(\n",
    "            mnist.target, classes=IMAGE_RANGE\n",
    "        ).astype(np.float32).reshape((-1, 10))\n",
    "    return features(), labels()\n",
    "\n",
    "\n",
    "# Download the MNIST dataset\n",
    "mnist            = fetch_mldata('MNIST original', data_home='.')\n",
    "features, labels = process(mnist)\n",
    "\n",
    "# Split train and test data\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)\n",
    "\n",
    "# Display feature and label shapes\n",
    "print('features:', features.shape, 'labels:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CNTK 2.0 CPU'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import CNTK\n",
    "import cntk as c\n",
    "\n",
    "# Display CNTK version\n",
    "' '.join([\n",
    "    c.__name__.upper(),\n",
    "    c.__version__,\n",
    "    str(c.device.all_devices()[0])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvNet():\n",
    "    IMAGE_SHAPE         = (1, 28, 28)\n",
    "    IMAGE_CLASSES       = [n for n in IMAGE_RANGE]\n",
    "    IMAGE_CLASS_COUNT   = len(IMAGE_CLASSES)\n",
    "    LEARNING_RATE       = [0.2] * 20 + [0.1] * 20 + [0.0001] * 20 + [0.00001] * 20\n",
    "    DEFAULT_EPOCH_COUNT = 80\n",
    "    DEFAULT_BATCH_SIZE  = 512\n",
    "    \n",
    "    def __init__(self,\n",
    "                 epoch_count=DEFAULT_EPOCH_COUNT,\n",
    "                 batch_size=DEFAULT_BATCH_SIZE):\n",
    "        self.epoch_count = epoch_count\n",
    "        self.batch_size  = batch_size\n",
    "        self._build()\n",
    "    \n",
    "    def evaluate(self, fn, feeds):\n",
    "        # Evaluate a function for each epoch with minibatched \n",
    "        # feed data. Used for training and testing the model.\n",
    "        for epoch in range(self.epoch_count):\n",
    "            batch = self.batch(epoch, feeds)\n",
    "            fn(epoch, batch)\n",
    "    \n",
    "    def train(self, data):\n",
    "        self.trainer.train_minibatch(data)\n",
    "    \n",
    "    def test(self, data):\n",
    "        self.trainer.test_minibatch(data)\n",
    "    \n",
    "    def log_train_progress(self):\n",
    "        self.trainer.summarize_training_progress()\n",
    "    \n",
    "    def log_test_progress(self):\n",
    "        self.trainer.summarize_test_progress()\n",
    "    \n",
    "    def log_parameters(self):\n",
    "        c.logging.log_number_of_parameters(self.stack)\n",
    "        print()\n",
    "    \n",
    "    def save(self, version):\n",
    "        self.stack.save(self._to_file(version))\n",
    "    \n",
    "    def restore(self, version):\n",
    "        self.stack.restore(self._to_file(version))\n",
    "    \n",
    "    def batch(self, epoch, data):\n",
    "        # Slice data into batch chunks based on the current epoch\n",
    "        def chunk(data):\n",
    "            slice_begin = epoch * self.batch_size\n",
    "            slice_end   = slice_begin + self.batch_size\n",
    "            return data[slice_begin:slice_end]\n",
    "        return {key: chunk(value) for key, value in data.items()}\n",
    "    \n",
    "    def _to_file(self, name):\n",
    "        file_names = [\n",
    "            self.__class__.__name__, 'MNIST', '{}.dnn'.format(name)\n",
    "        ]\n",
    "        return os.path.join(\n",
    "            '.', 'checkpoints', '_'.join(file_names)\n",
    "        )\n",
    "    \n",
    "    def _build(self):\n",
    "        self._build_inputs()\n",
    "        self._build_layers()\n",
    "        self._build_stack()\n",
    "        self._build_trainer()\n",
    "    \n",
    "    def _build_inputs(self):\n",
    "        # Define input variables of neural net\n",
    "        self.features = c.input_variable(self.IMAGE_SHAPE,       np.float32, name='features')\n",
    "        self.labels   = c.input_variable(self.IMAGE_CLASS_COUNT, np.float32, name='labels')\n",
    "    \n",
    "    def _build_layers(self):\n",
    "        # Define neural net layers\n",
    "        with c.layers.default_options(activation=c.ops.relu, pad=False):\n",
    "            self.layers  = [\n",
    "                c.layers.Convolution2D((5,5), 32, pad=True),\n",
    "                c.layers.MaxPooling((3,3), (2,2)),\n",
    "                c.layers.Convolution2D((3,3), 48),\n",
    "                c.layers.MaxPooling((3,3), (2,2)),\n",
    "                c.layers.Convolution2D((3,3), 64),\n",
    "                c.layers.Dense(96),\n",
    "                c.layers.Dropout(0.8),\n",
    "                c.layers.Dense(self.IMAGE_CLASS_COUNT, activation=None)\n",
    "            ]\n",
    "    \n",
    "    def _build_stack(self):\n",
    "        # Stack neural net layers into model\n",
    "        self.stack = self.features\n",
    "        for layer in self.layers: self.stack = layer(self.stack)\n",
    "        self.loss  = c.losses.cross_entropy_with_softmax(self.stack, self.labels)\n",
    "        self.error = c.metrics.classification_error(self.stack, self.labels)\n",
    "    \n",
    "    def _build_trainer(self):\n",
    "        # Define neural net trainer\n",
    "        schedule     = c.learning_rate_schedule(self.LEARNING_RATE, c.UnitType.minibatch)\n",
    "        learner      = c.learners.sgd(self.stack.parameters, schedule)\n",
    "        printer      = c.logging.ProgressPrinter(tag='Training', num_epochs=self.epoch_count)\n",
    "        self.trainer = c.Trainer(self.stack, (self.loss, self.error), learner, printer)\n",
    "    \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, type, value, traceback):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 98778 parameters in 10 parameter tensors.\n",
      "\n",
      "Learning rate per minibatch: 0.2\n",
      "Finished Epoch[1 of 80]: [Training] loss = 2.313337 * 512, metric = 89.06% * 512 2.460s (208.1 samples/s);\n",
      "Finished Epoch[2 of 80]: [Training] loss = 2.299743 * 512, metric = 88.48% * 512 0.902s (567.6 samples/s);\n",
      "Finished Epoch[3 of 80]: [Training] loss = 2.302219 * 512, metric = 88.28% * 512 1.215s (421.4 samples/s);\n",
      "Finished Epoch[4 of 80]: [Training] loss = 2.276180 * 512, metric = 87.89% * 512 0.972s (526.7 samples/s);\n",
      "Finished Epoch[5 of 80]: [Training] loss = 2.281023 * 512, metric = 86.72% * 512 1.807s (283.3 samples/s);\n",
      "Finished Epoch[6 of 80]: [Training] loss = 2.274911 * 512, metric = 85.74% * 512 1.533s (334.0 samples/s);\n",
      "Finished Epoch[7 of 80]: [Training] loss = 2.274856 * 512, metric = 87.11% * 512 1.536s (333.3 samples/s);\n",
      "Finished Epoch[8 of 80]: [Training] loss = 2.258026 * 512, metric = 80.86% * 512 1.086s (471.5 samples/s);\n",
      "Finished Epoch[9 of 80]: [Training] loss = 2.248255 * 512, metric = 82.23% * 512 1.031s (496.6 samples/s);\n",
      "Finished Epoch[10 of 80]: [Training] loss = 2.222235 * 512, metric = 80.27% * 512 0.945s (541.8 samples/s);\n",
      "Finished Epoch[11 of 80]: [Training] loss = 2.242574 * 512, metric = 82.62% * 512 1.497s (342.0 samples/s);\n",
      "Finished Epoch[12 of 80]: [Training] loss = 2.222973 * 512, metric = 79.49% * 512 1.418s (361.1 samples/s);\n",
      "Finished Epoch[13 of 80]: [Training] loss = 2.244472 * 512, metric = 83.98% * 512 1.098s (466.3 samples/s);\n",
      "Finished Epoch[14 of 80]: [Training] loss = 2.194860 * 512, metric = 78.91% * 512 1.066s (480.3 samples/s);\n",
      "Finished Epoch[15 of 80]: [Training] loss = 2.181645 * 512, metric = 77.54% * 512 0.965s (530.6 samples/s);\n",
      "Finished Epoch[16 of 80]: [Training] loss = 2.174394 * 512, metric = 74.02% * 512 0.956s (535.6 samples/s);\n",
      "Finished Epoch[17 of 80]: [Training] loss = 2.136981 * 512, metric = 74.02% * 512 1.004s (510.0 samples/s);\n",
      "Finished Epoch[18 of 80]: [Training] loss = 2.117769 * 512, metric = 76.76% * 512 1.028s (498.1 samples/s);\n",
      "Finished Epoch[19 of 80]: [Training] loss = 2.129702 * 512, metric = 78.32% * 512 0.976s (524.6 samples/s);\n",
      "Finished Epoch[20 of 80]: [Training] loss = 2.114858 * 512, metric = 75.98% * 512 0.971s (527.3 samples/s);\n",
      "Finished Epoch[21 of 80]: [Training] loss = 2.046253 * 512, metric = 73.05% * 512 1.291s (396.6 samples/s);\n",
      "Finished Epoch[22 of 80]: [Training] loss = 2.021453 * 512, metric = 72.66% * 512 0.981s (521.9 samples/s);\n",
      "Finished Epoch[23 of 80]: [Training] loss = 2.092407 * 512, metric = 73.24% * 512 0.964s (531.1 samples/s);\n",
      "Finished Epoch[24 of 80]: [Training] loss = 2.022983 * 512, metric = 70.70% * 512 0.921s (555.9 samples/s);\n",
      "Finished Epoch[25 of 80]: [Training] loss = 1.975283 * 512, metric = 67.77% * 512 0.932s (549.4 samples/s);\n",
      "Finished Epoch[26 of 80]: [Training] loss = 1.917562 * 512, metric = 68.16% * 512 0.947s (540.7 samples/s);\n",
      "Finished Epoch[27 of 80]: [Training] loss = 2.010669 * 512, metric = 67.38% * 512 1.144s (447.6 samples/s);\n",
      "Finished Epoch[28 of 80]: [Training] loss = 1.983409 * 512, metric = 68.55% * 512 0.982s (521.4 samples/s);\n",
      "Finished Epoch[29 of 80]: [Training] loss = 2.004819 * 512, metric = 70.90% * 512 0.972s (526.7 samples/s);\n",
      "Finished Epoch[30 of 80]: [Training] loss = 2.045819 * 512, metric = 74.61% * 512 0.921s (555.9 samples/s);\n",
      "Finished Epoch[31 of 80]: [Training] loss = 1.815029 * 512, metric = 61.52% * 512 0.920s (556.5 samples/s);\n",
      "Finished Epoch[32 of 80]: [Training] loss = 1.749438 * 512, metric = 58.98% * 512 0.922s (555.3 samples/s);\n",
      "Finished Epoch[33 of 80]: [Training] loss = 1.649284 * 512, metric = 58.59% * 512 0.931s (549.9 samples/s);\n",
      "Finished Epoch[34 of 80]: [Training] loss = 1.723770 * 512, metric = 61.33% * 512 0.939s (545.3 samples/s);\n",
      "Finished Epoch[35 of 80]: [Training] loss = 1.839996 * 512, metric = 66.80% * 512 1.165s (439.5 samples/s);\n",
      "Finished Epoch[36 of 80]: [Training] loss = 1.697462 * 512, metric = 54.10% * 512 1.713s (298.9 samples/s);\n",
      "Finished Epoch[37 of 80]: [Training] loss = 1.569599 * 512, metric = 53.91% * 512 1.083s (472.8 samples/s);\n",
      "Finished Epoch[38 of 80]: [Training] loss = 1.471172 * 512, metric = 50.59% * 512 0.976s (524.6 samples/s);\n",
      "Finished Epoch[39 of 80]: [Training] loss = 1.644217 * 512, metric = 56.84% * 512 0.977s (524.1 samples/s);\n",
      "Finished Epoch[40 of 80]: [Training] loss = 1.885887 * 512, metric = 68.75% * 512 0.928s (551.7 samples/s);\n",
      "Finished Epoch[41 of 80]: [Training] loss = 1.673364 * 512, metric = 58.01% * 512 0.940s (544.7 samples/s);\n",
      "Finished Epoch[42 of 80]: [Training] loss = 1.536742 * 512, metric = 56.25% * 512 0.921s (555.9 samples/s);\n",
      "Finished Epoch[43 of 80]: [Training] loss = 1.396495 * 512, metric = 50.39% * 512 0.919s (557.1 samples/s);\n",
      "Finished Epoch[44 of 80]: [Training] loss = 1.327182 * 512, metric = 46.48% * 512 0.921s (555.9 samples/s);\n",
      "Finished Epoch[45 of 80]: [Training] loss = 1.305390 * 512, metric = 43.36% * 512 0.911s (562.0 samples/s);\n",
      "Finished Epoch[46 of 80]: [Training] loss = 1.379028 * 512, metric = 49.02% * 512 1.052s (486.7 samples/s);\n",
      "Finished Epoch[47 of 80]: [Training] loss = 1.526927 * 512, metric = 53.52% * 512 1.729s (296.1 samples/s);\n",
      "Finished Epoch[48 of 80]: [Training] loss = 1.486525 * 512, metric = 53.71% * 512 1.517s (337.5 samples/s);\n",
      "Finished Epoch[49 of 80]: [Training] loss = 1.356307 * 512, metric = 44.14% * 512 1.546s (331.2 samples/s);\n",
      "Finished Epoch[50 of 80]: [Training] loss = 1.168385 * 512, metric = 41.21% * 512 1.119s (457.6 samples/s);\n",
      "Finished Epoch[51 of 80]: [Training] loss = 1.195639 * 512, metric = 37.50% * 512 1.017s (503.4 samples/s);\n",
      "Finished Epoch[52 of 80]: [Training] loss = 1.369136 * 512, metric = 49.61% * 512 0.997s (513.5 samples/s);\n",
      "Finished Epoch[53 of 80]: [Training] loss = 1.351959 * 512, metric = 46.09% * 512 0.972s (526.7 samples/s);\n",
      "Finished Epoch[54 of 80]: [Training] loss = 1.212623 * 512, metric = 39.45% * 512 1.248s (410.3 samples/s);\n",
      "Finished Epoch[55 of 80]: [Training] loss = 1.123544 * 512, metric = 38.09% * 512 1.046s (489.5 samples/s);\n",
      "Finished Epoch[56 of 80]: [Training] loss = 1.026628 * 512, metric = 34.77% * 512 1.181s (433.5 samples/s);\n",
      "Finished Epoch[57 of 80]: [Training] loss = 0.988920 * 512, metric = 34.57% * 512 1.117s (458.4 samples/s);\n",
      "Finished Epoch[58 of 80]: [Training] loss = 1.042234 * 512, metric = 36.72% * 512 0.961s (532.8 samples/s);\n",
      "Finished Epoch[59 of 80]: [Training] loss = 1.043076 * 512, metric = 39.06% * 512 0.939s (545.3 samples/s);\n",
      "Finished Epoch[60 of 80]: [Training] loss = 1.175451 * 512, metric = 42.77% * 512 0.928s (551.7 samples/s);\n",
      "Finished Epoch[61 of 80]: [Training] loss = 1.313024 * 512, metric = 42.19% * 512 1.095s (467.6 samples/s);\n",
      "Finished Epoch[62 of 80]: [Training] loss = 1.258940 * 512, metric = 43.36% * 512 0.878s (583.1 samples/s);\n",
      "Finished Epoch[63 of 80]: [Training] loss = 1.095016 * 512, metric = 35.35% * 512 1.515s (338.0 samples/s);\n",
      "Finished Epoch[64 of 80]: [Training] loss = 0.999256 * 512, metric = 33.40% * 512 1.097s (466.7 samples/s);\n",
      "Finished Epoch[65 of 80]: [Training] loss = 1.017329 * 512, metric = 32.42% * 512 1.865s (274.5 samples/s);\n",
      "Finished Epoch[66 of 80]: [Training] loss = 0.949434 * 512, metric = 31.64% * 512 1.592s (321.6 samples/s);\n",
      "Finished Epoch[67 of 80]: [Training] loss = 0.813639 * 512, metric = 26.95% * 512 0.972s (526.7 samples/s);\n",
      "Finished Epoch[68 of 80]: [Training] loss = 0.927847 * 512, metric = 32.42% * 512 0.933s (548.8 samples/s);\n",
      "Finished Epoch[69 of 80]: [Training] loss = 0.777688 * 512, metric = 24.02% * 512 1.590s (322.0 samples/s);\n",
      "Finished Epoch[70 of 80]: [Training] loss = 0.738088 * 512, metric = 23.24% * 512 1.676s (305.5 samples/s);\n",
      "Finished Epoch[71 of 80]: [Training] loss = 0.807398 * 512, metric = 25.59% * 512 1.625s (315.1 samples/s);\n",
      "Finished Epoch[72 of 80]: [Training] loss = 1.010865 * 512, metric = 35.94% * 512 1.357s (377.3 samples/s);\n",
      "Finished Epoch[73 of 80]: [Training] loss = 1.116782 * 512, metric = 39.06% * 512 1.018s (502.9 samples/s);\n",
      "Finished Epoch[74 of 80]: [Training] loss = 1.124866 * 512, metric = 36.72% * 512 1.731s (295.8 samples/s);\n",
      "Finished Epoch[75 of 80]: [Training] loss = 1.031574 * 512, metric = 35.35% * 512 0.959s (533.9 samples/s);\n",
      "Finished Epoch[76 of 80]: [Training] loss = 0.885871 * 512, metric = 26.37% * 512 1.711s (299.2 samples/s);\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch[77 of 80]: [Training] loss = 0.758766 * 512, metric = 24.02% * 512 1.210s (423.1 samples/s);\n",
      "Finished Epoch[78 of 80]: [Training] loss = 0.795428 * 512, metric = 27.73% * 512 1.009s (507.4 samples/s);\n",
      "Finished Epoch[79 of 80]: [Training] loss = 0.722301 * 512, metric = 27.15% * 512 0.975s (525.1 samples/s);\n",
      "Finished Epoch[80 of 80]: [Training] loss = 0.623668 * 512, metric = 19.92% * 512 0.927s (552.3 samples/s);\n"
     ]
    }
   ],
   "source": [
    "with ConvNet() as cnn:\n",
    "    # Train the model and save state to a checkpoint file\n",
    "    def train(epoch, batch_map):\n",
    "        cnn.train(batch_map)\n",
    "        cnn.log_train_progress()\n",
    "    cnn.log_parameters()\n",
    "    cnn.evaluate(train, {'features': train_features, 'labels': train_labels})\n",
    "    cnn.save('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 98778 parameters in 10 parameter tensors.\n",
      "\n",
      "Finished Evaluation [1]: Minibatch[1-1]: metric = 7.81% * 512;\n",
      "Finished Evaluation [2]: Minibatch[1-1]: metric = 8.20% * 512;\n",
      "Finished Evaluation [3]: Minibatch[1-1]: metric = 8.01% * 512;\n",
      "Finished Evaluation [4]: Minibatch[1-1]: metric = 9.38% * 512;\n",
      "Finished Evaluation [5]: Minibatch[1-1]: metric = 9.96% * 512;\n"
     ]
    }
   ],
   "source": [
    "with ConvNet(epoch_count=5) as cnn:\n",
    "    # Restore state from a checkpoint file and test the model \n",
    "    def test(epoch, batch_map):\n",
    "        cnn.test(batch_map)\n",
    "        cnn.log_test_progress()\n",
    "    cnn.log_parameters()\n",
    "    cnn.restore('train')\n",
    "    cnn.evaluate(test, {'features': train_features, 'labels': train_labels})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
