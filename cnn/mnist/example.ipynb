{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: (70000, 1, 28, 28) labels: (70000, 10)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.datasets        import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing   import label_binarize\n",
    "\n",
    "PIXEL_RANGE = range(0, 255 + 1)\n",
    "IMAGE_RANGE = range(0, 9 + 1)\n",
    "\n",
    "def process(mnist):\n",
    "    # Process dataset to return features and labels for CNN\n",
    "    def features():\n",
    "        # Transform features to be float32 sets of 1x28x28 \n",
    "        # tensors with normalized pixel values.\n",
    "        return np.divide(\n",
    "            mnist.data, PIXEL_RANGE[-1]\n",
    "        ).astype(np.float32).reshape((-1, 1, 28, 28))\n",
    "    def labels():\n",
    "        # Transform labels to be float32 sets of 1x10\n",
    "        # tensors that are one-hot encoded.\n",
    "        return label_binarize(\n",
    "            mnist.target, classes=IMAGE_RANGE\n",
    "        ).astype(np.float32).reshape((-1, 10))\n",
    "    return features(), labels()\n",
    "\n",
    "\n",
    "# Download the MNIST dataset\n",
    "mnist            = fetch_mldata('MNIST original', data_home='.')\n",
    "features, labels = process(mnist)\n",
    "\n",
    "# Split train and test data\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)\n",
    "\n",
    "# Display feature and label shapes\n",
    "print('features:', features.shape, 'labels:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CNTK 2.0 CPU'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import CNTK\n",
    "import cntk as c\n",
    "\n",
    "# Display CNTK version\n",
    "' '.join([\n",
    "    c.__name__.upper(),\n",
    "    c.__version__,\n",
    "    str(c.device.all_devices()[0])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvNet():\n",
    "    IMAGE_SHAPE       = (1, 28, 28)\n",
    "    IMAGE_CLASSES     = [n for n in IMAGE_RANGE]\n",
    "    IMAGE_CLASS_COUNT = len(IMAGE_CLASSES)\n",
    "    LEARNING_RATE     = [0.2] * 20 + [0.1] * 20 + [0.0001] * 20 + [0.00001] * 20\n",
    "    EPOCH_COUNT       = 80\n",
    "    BATCH_SIZE        = 512\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._build_inputs()\n",
    "        self._build_layers()\n",
    "        self._build_stack()\n",
    "        self._build_trainer()\n",
    "    \n",
    "    def evaluate(self, fn, feeds):\n",
    "        for epoch in range(self.EPOCH_COUNT):\n",
    "            batch = self.batch(epoch, feeds)\n",
    "            fn(epoch, batch)\n",
    "    \n",
    "    def train(self, data):\n",
    "        self.trainer.train_minibatch(data)\n",
    "    \n",
    "    def log_progress(self):\n",
    "        self.trainer.summarize_training_progress()\n",
    "    \n",
    "    def log_parameters(self):\n",
    "        c.logging.log_number_of_parameters(self.stack)\n",
    "        print()\n",
    "    \n",
    "    def checkpoint(self, version):\n",
    "        file_names = [\n",
    "            self.__class__.__name__, 'MNIST', '{}.dnn'.format(version)\n",
    "        ]\n",
    "        self.stack.save(\n",
    "            os.path.join('.', 'checkpoints', '_'.join(file_names))\n",
    "        )\n",
    "    \n",
    "    def batch(self, epoch, data):\n",
    "        def chunk(data):\n",
    "            slice_begin = epoch * self.BATCH_SIZE\n",
    "            slice_end   = slice_begin + self.BATCH_SIZE\n",
    "            return data[slice_begin:slice_end]\n",
    "        return {key: chunk(value) for key, value in data.items()}\n",
    "    \n",
    "    def _build_inputs(self):\n",
    "        self.features = c.input_variable(self.IMAGE_SHAPE,       np.float32, name='features')\n",
    "        self.labels   = c.input_variable(self.IMAGE_CLASS_COUNT, np.float32, name='labels')\n",
    "    \n",
    "    def _build_layers(self):\n",
    "        with c.layers.default_options(activation=c.ops.relu, pad=False):\n",
    "            self.layers  = [\n",
    "                c.layers.Convolution2D((5,5), 32, pad=True),\n",
    "                c.layers.MaxPooling((3,3), (2,2)),\n",
    "                c.layers.Convolution2D((3,3), 48),\n",
    "                c.layers.MaxPooling((3,3), (2,2)),\n",
    "                c.layers.Convolution2D((3,3), 64),\n",
    "                c.layers.Dense(96),\n",
    "                c.layers.Dropout(0.8),\n",
    "                c.layers.Dense(self.IMAGE_CLASS_COUNT, activation=None)\n",
    "            ]\n",
    "    \n",
    "    def _build_stack(self):\n",
    "        self.stack = self.features\n",
    "        for layer in self.layers: self.stack = layer(self.stack)\n",
    "        self.loss  = c.losses.cross_entropy_with_softmax(self.stack, self.labels)\n",
    "        self.error = c.metrics.classification_error(self.stack, self.labels)\n",
    "    \n",
    "    def _build_trainer(self):\n",
    "        schedule     = c.learning_rate_schedule(self.LEARNING_RATE, c.UnitType.minibatch)\n",
    "        learner      = c.learners.sgd(self.stack.parameters, schedule)\n",
    "        printer      = c.logging.ProgressPrinter(tag='Training', num_epochs=self.EPOCH_COUNT)\n",
    "        self.trainer = c.Trainer(self.stack, (self.loss, self.error), learner, printer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 98778 parameters in 10 parameter tensors.\n",
      "\n",
      "Learning rate per minibatch: 0.2\n",
      "Finished Epoch[1 of 80]: [Training] loss = 2.335645 * 512, metric = 90.43% * 512 3.056s (167.5 samples/s);\n",
      "Finished Epoch[2 of 80]: [Training] loss = 2.299878 * 512, metric = 89.26% * 512 1.133s (451.9 samples/s);\n",
      "Finished Epoch[3 of 80]: [Training] loss = 2.288602 * 512, metric = 86.72% * 512 0.904s (566.4 samples/s);\n",
      "Finished Epoch[4 of 80]: [Training] loss = 2.279175 * 512, metric = 84.77% * 512 1.049s (488.1 samples/s);\n",
      "Finished Epoch[5 of 80]: [Training] loss = 2.272207 * 512, metric = 84.96% * 512 1.006s (508.9 samples/s);\n",
      "Finished Epoch[6 of 80]: [Training] loss = 2.275580 * 512, metric = 84.57% * 512 0.905s (565.7 samples/s);\n",
      "Finished Epoch[7 of 80]: [Training] loss = 2.259426 * 512, metric = 83.40% * 512 1.824s (280.7 samples/s);\n",
      "Finished Epoch[8 of 80]: [Training] loss = 2.260013 * 512, metric = 83.20% * 512 1.168s (438.4 samples/s);\n",
      "Finished Epoch[9 of 80]: [Training] loss = 2.237940 * 512, metric = 83.98% * 512 0.901s (568.3 samples/s);\n",
      "Finished Epoch[10 of 80]: [Training] loss = 2.240731 * 512, metric = 80.86% * 512 1.073s (477.2 samples/s);\n",
      "Finished Epoch[11 of 80]: [Training] loss = 2.225843 * 512, metric = 82.81% * 512 1.217s (420.7 samples/s);\n",
      "Finished Epoch[12 of 80]: [Training] loss = 2.201619 * 512, metric = 82.62% * 512 1.059s (483.5 samples/s);\n",
      "Finished Epoch[13 of 80]: [Training] loss = 2.202915 * 512, metric = 79.10% * 512 1.061s (482.6 samples/s);\n",
      "Finished Epoch[14 of 80]: [Training] loss = 2.209535 * 512, metric = 80.27% * 512 1.037s (493.7 samples/s);\n",
      "Finished Epoch[15 of 80]: [Training] loss = 2.180723 * 512, metric = 77.34% * 512 0.939s (545.3 samples/s);\n",
      "Finished Epoch[16 of 80]: [Training] loss = 2.199269 * 512, metric = 79.69% * 512 1.057s (484.4 samples/s);\n",
      "Finished Epoch[17 of 80]: [Training] loss = 2.163693 * 512, metric = 73.63% * 512 1.014s (504.9 samples/s);\n",
      "Finished Epoch[18 of 80]: [Training] loss = 2.071082 * 512, metric = 69.53% * 512 1.051s (487.2 samples/s);\n",
      "Finished Epoch[19 of 80]: [Training] loss = 2.096974 * 512, metric = 77.54% * 512 0.992s (516.1 samples/s);\n",
      "Finished Epoch[20 of 80]: [Training] loss = 2.192930 * 512, metric = 80.27% * 512 0.979s (523.0 samples/s);\n",
      "Finished Epoch[21 of 80]: [Training] loss = 2.152053 * 512, metric = 74.80% * 512 1.397s (366.5 samples/s);\n",
      "Finished Epoch[22 of 80]: [Training] loss = 2.035266 * 512, metric = 69.34% * 512 1.328s (385.5 samples/s);\n",
      "Finished Epoch[23 of 80]: [Training] loss = 2.017110 * 512, metric = 67.97% * 512 1.008s (507.9 samples/s);\n",
      "Finished Epoch[24 of 80]: [Training] loss = 2.165769 * 512, metric = 80.47% * 512 0.962s (532.2 samples/s);\n",
      "Finished Epoch[25 of 80]: [Training] loss = 2.052574 * 512, metric = 69.34% * 512 1.317s (388.8 samples/s);\n",
      "Finished Epoch[26 of 80]: [Training] loss = 1.956702 * 512, metric = 64.26% * 512 1.079s (474.5 samples/s);\n",
      "Finished Epoch[27 of 80]: [Training] loss = 1.816524 * 512, metric = 58.59% * 512 1.176s (435.4 samples/s);\n",
      "Finished Epoch[28 of 80]: [Training] loss = 1.801848 * 512, metric = 60.55% * 512 0.958s (534.4 samples/s);\n",
      "Finished Epoch[29 of 80]: [Training] loss = 1.876164 * 512, metric = 66.60% * 512 1.297s (394.8 samples/s);\n",
      "Finished Epoch[30 of 80]: [Training] loss = 1.714099 * 512, metric = 58.98% * 512 1.021s (501.5 samples/s);\n",
      "Finished Epoch[31 of 80]: [Training] loss = 1.605098 * 512, metric = 52.93% * 512 1.017s (503.4 samples/s);\n",
      "Finished Epoch[32 of 80]: [Training] loss = 1.560891 * 512, metric = 54.30% * 512 1.194s (428.8 samples/s);\n",
      "Finished Epoch[33 of 80]: [Training] loss = 1.524167 * 512, metric = 53.52% * 512 1.161s (441.0 samples/s);\n",
      "Finished Epoch[34 of 80]: [Training] loss = 1.522756 * 512, metric = 50.39% * 512 0.994s (515.1 samples/s);\n",
      "Finished Epoch[35 of 80]: [Training] loss = 1.826877 * 512, metric = 62.89% * 512 1.010s (506.9 samples/s);\n",
      "Finished Epoch[36 of 80]: [Training] loss = 1.688034 * 512, metric = 61.13% * 512 1.065s (480.8 samples/s);\n",
      "Finished Epoch[37 of 80]: [Training] loss = 1.511379 * 512, metric = 51.37% * 512 1.025s (499.5 samples/s);\n",
      "Finished Epoch[38 of 80]: [Training] loss = 1.434958 * 512, metric = 49.41% * 512 1.003s (510.5 samples/s);\n",
      "Finished Epoch[39 of 80]: [Training] loss = 1.422810 * 512, metric = 47.27% * 512 1.295s (395.4 samples/s);\n",
      "Finished Epoch[40 of 80]: [Training] loss = 1.336577 * 512, metric = 44.53% * 512 0.998s (513.0 samples/s);\n",
      "Finished Epoch[41 of 80]: [Training] loss = 1.383539 * 512, metric = 45.90% * 512 0.955s (536.1 samples/s);\n",
      "Finished Epoch[42 of 80]: [Training] loss = 1.419528 * 512, metric = 50.00% * 512 0.910s (562.6 samples/s);\n",
      "Finished Epoch[43 of 80]: [Training] loss = 1.367299 * 512, metric = 49.22% * 512 0.925s (553.5 samples/s);\n",
      "Finished Epoch[44 of 80]: [Training] loss = 1.254136 * 512, metric = 41.21% * 512 0.917s (558.3 samples/s);\n",
      "Finished Epoch[45 of 80]: [Training] loss = 1.209921 * 512, metric = 43.16% * 512 0.928s (551.7 samples/s);\n",
      "Finished Epoch[46 of 80]: [Training] loss = 1.217180 * 512, metric = 42.19% * 512 0.913s (560.8 samples/s);\n",
      "Finished Epoch[47 of 80]: [Training] loss = 1.065432 * 512, metric = 36.72% * 512 0.916s (559.0 samples/s);\n",
      "Finished Epoch[48 of 80]: [Training] loss = 1.290985 * 512, metric = 42.77% * 512 0.922s (555.3 samples/s);\n",
      "Finished Epoch[49 of 80]: [Training] loss = 1.309913 * 512, metric = 44.92% * 512 0.909s (563.3 samples/s);\n",
      "Finished Epoch[50 of 80]: [Training] loss = 1.314706 * 512, metric = 41.80% * 512 0.915s (559.6 samples/s);\n",
      "Finished Epoch[51 of 80]: [Training] loss = 1.076615 * 512, metric = 35.55% * 512 0.910s (562.6 samples/s);\n",
      "Finished Epoch[52 of 80]: [Training] loss = 1.015099 * 512, metric = 33.40% * 512 0.962s (532.2 samples/s);\n",
      "Finished Epoch[53 of 80]: [Training] loss = 0.999226 * 512, metric = 33.59% * 512 0.905s (565.7 samples/s);\n",
      "Finished Epoch[54 of 80]: [Training] loss = 1.578336 * 512, metric = 52.15% * 512 1.188s (431.0 samples/s);\n",
      "Finished Epoch[55 of 80]: [Training] loss = 1.847480 * 512, metric = 58.79% * 512 1.166s (439.1 samples/s);\n",
      "Finished Epoch[56 of 80]: [Training] loss = 1.592110 * 512, metric = 49.41% * 512 0.991s (516.6 samples/s);\n",
      "Finished Epoch[57 of 80]: [Training] loss = 1.217573 * 512, metric = 35.74% * 512 0.940s (544.7 samples/s);\n",
      "Finished Epoch[58 of 80]: [Training] loss = 1.125722 * 512, metric = 37.50% * 512 0.909s (563.3 samples/s);\n",
      "Finished Epoch[59 of 80]: [Training] loss = 1.096904 * 512, metric = 37.70% * 512 1.159s (441.8 samples/s);\n",
      "Finished Epoch[60 of 80]: [Training] loss = 1.029256 * 512, metric = 33.59% * 512 1.045s (490.0 samples/s);\n",
      "Finished Epoch[61 of 80]: [Training] loss = 0.988832 * 512, metric = 30.86% * 512 1.061s (482.6 samples/s);\n",
      "Finished Epoch[62 of 80]: [Training] loss = 1.015573 * 512, metric = 34.77% * 512 0.969s (528.4 samples/s);\n",
      "Finished Epoch[63 of 80]: [Training] loss = 0.918957 * 512, metric = 32.23% * 512 0.975s (525.1 samples/s);\n",
      "Finished Epoch[64 of 80]: [Training] loss = 0.988489 * 512, metric = 35.74% * 512 0.918s (557.7 samples/s);\n",
      "Finished Epoch[65 of 80]: [Training] loss = 1.249552 * 512, metric = 41.02% * 512 0.954s (536.7 samples/s);\n",
      "Finished Epoch[66 of 80]: [Training] loss = 1.210053 * 512, metric = 43.55% * 512 0.920s (556.5 samples/s);\n",
      "Finished Epoch[67 of 80]: [Training] loss = 0.931063 * 512, metric = 27.73% * 512 0.916s (559.0 samples/s);\n",
      "Finished Epoch[68 of 80]: [Training] loss = 0.893369 * 512, metric = 27.73% * 512 0.920s (556.5 samples/s);\n",
      "Finished Epoch[69 of 80]: [Training] loss = 0.840562 * 512, metric = 28.32% * 512 1.112s (460.4 samples/s);\n",
      "Finished Epoch[70 of 80]: [Training] loss = 0.807919 * 512, metric = 27.34% * 512 1.028s (498.1 samples/s);\n",
      "Finished Epoch[71 of 80]: [Training] loss = 0.902842 * 512, metric = 29.10% * 512 0.968s (528.9 samples/s);\n",
      "Finished Epoch[72 of 80]: [Training] loss = 1.028866 * 512, metric = 35.94% * 512 1.016s (503.9 samples/s);\n",
      "Finished Epoch[73 of 80]: [Training] loss = 0.856968 * 512, metric = 29.10% * 512 1.066s (480.3 samples/s);\n",
      "Finished Epoch[74 of 80]: [Training] loss = 0.760981 * 512, metric = 25.78% * 512 1.014s (504.9 samples/s);\n",
      "Finished Epoch[75 of 80]: [Training] loss = 0.743242 * 512, metric = 23.83% * 512 0.981s (521.9 samples/s);\n",
      "Finished Epoch[76 of 80]: [Training] loss = 0.829611 * 512, metric = 24.41% * 512 0.963s (531.7 samples/s);\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch[77 of 80]: [Training] loss = 0.698961 * 512, metric = 21.09% * 512 0.965s (530.6 samples/s);\n",
      "Finished Epoch[78 of 80]: [Training] loss = 0.668837 * 512, metric = 20.90% * 512 0.921s (555.9 samples/s);\n",
      "Finished Epoch[79 of 80]: [Training] loss = 0.664158 * 512, metric = 23.63% * 512 0.913s (560.8 samples/s);\n",
      "Finished Epoch[80 of 80]: [Training] loss = 0.708523 * 512, metric = 23.83% * 512 0.913s (560.8 samples/s);\n"
     ]
    }
   ],
   "source": [
    "cnn = ConvNet()\n",
    "def train(epoch, batch_map):\n",
    "    cnn.train(batch_map)\n",
    "    cnn.log_progress()\n",
    "cnn.log_parameters()\n",
    "cnn.evaluate(train, {'features': train_features, 'labels': train_labels})\n",
    "cnn.checkpoint('train')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
