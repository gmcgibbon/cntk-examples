{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets        import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing   import label_binarize\n",
    "\n",
    "PIXEL_RANGE = range(0, 255 + 1)\n",
    "IMAGE_RANGE = range(0, 9 + 1)\n",
    "\n",
    "def process(mnist):\n",
    "    # Process dataset to return features and labels for CNN\n",
    "    def features():\n",
    "        # Transform features to be float32 sets of 1x28x28 \n",
    "        # tensors with normalized pixel values.\n",
    "        return np.divide(\n",
    "            mnist.data, PIXEL_RANGE[-1]\n",
    "        ).astype(np.float32).reshape((-1, 1, 28, 28))\n",
    "    def labels():\n",
    "        # Transform labels to be float32 sets of 1x10\n",
    "        # tensors that are one-hot encoded.\n",
    "        return label_binarize(\n",
    "            mnist.target, classes=IMAGE_RANGE\n",
    "        ).astype(np.float32).reshape((-1, 10))\n",
    "    return features(), labels()\n",
    "\n",
    "\n",
    "# Download the MNIST dataset\n",
    "mnist            = fetch_mldata('MNIST original', data_home='.')\n",
    "features, labels = process(mnist)\n",
    "\n",
    "# Split train and test data\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CNTK 2.0 CPU'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import CNTK\n",
    "import cntk  as c\n",
    "\n",
    "# Display CNTK version\n",
    "' '.join([\n",
    "    c.__name__.upper(),\n",
    "    c.__version__,\n",
    "    str(c.device.all_devices()[0])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvNet():\n",
    "    IMAGE_SHAPE        = (1, 28, 28)\n",
    "    IMAGE_CLASSES      = [n for n in IMAGE_RANGE]\n",
    "    IMAGE_CLASS_COUNT  = len(IMAGE_CLASSES)\n",
    "    LEARNING_RATE      = 0.001\n",
    "    EPOCH_COUNT        = 20\n",
    "    BATCH_SIZE         = 64\n",
    "    DROP_RATE          = 0.5\n",
    "    HIDDEN_LAYER_COUNT = 96\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._build_inputs()\n",
    "        self._build_layers()\n",
    "        self._build_stack()\n",
    "        self._build_trainer()\n",
    "    \n",
    "    def evaluate(self, fn, feeds):\n",
    "        c.logging.log_number_of_parameters(self.stack); print()\n",
    "        for epoch in range(self.EPOCH_COUNT):\n",
    "            batch = self.batch(epoch, feeds)\n",
    "            fn(epoch, batch)\n",
    "    \n",
    "    def train(self, data):\n",
    "        self.trainer.train_minibatch(data)\n",
    "    \n",
    "    def summarize(self):\n",
    "        self.trainer.summarize_training_progress()\n",
    "    \n",
    "    def checkpoint(self, version):\n",
    "        self.stack.save(\n",
    "            os.path.join(\n",
    "                '.', '_'.join('ConvNet', 'MNIST', '{}.dnn'.format(version))\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def batch(self, epoch, data):\n",
    "        def chunk(data):\n",
    "            slice_begin = epoch * self.BATCH_SIZE\n",
    "            slice_end   = slice_begin + self.BATCH_SIZE\n",
    "            return data[slice_begin:slice_end]\n",
    "        return {key: chunk(value) for key, value in data.items()}\n",
    "    \n",
    "    def _build_inputs(self):\n",
    "        self.inputs = c.input_variable(self.IMAGE_SHAPE,       np.float32, name='inputs')\n",
    "        self.labels = c.input_variable(self.IMAGE_CLASS_COUNT, np.float32, name='labels')\n",
    "    \n",
    "    def _build_layers(self):\n",
    "        with c.layers.default_options(activation=c.ops.relu, pad=False):\n",
    "            self.layers  = [\n",
    "                c.layers.Convolution2D((5,5), 32, pad=True),\n",
    "                c.layers.MaxPooling((3,3), (2,2)),\n",
    "                c.layers.Convolution2D((3,3), 48),\n",
    "                c.layers.MaxPooling((3,3), (2,2)),\n",
    "                c.layers.Convolution2D((3,3), 64),\n",
    "                c.layers.Dense(self.HIDDEN_LAYER_COUNT),\n",
    "                c.layers.Dropout(self.DROP_RATE),\n",
    "                c.layers.Dense(self.IMAGE_CLASS_COUNT, activation=None)\n",
    "            ]\n",
    "    \n",
    "    def _build_stack(self):\n",
    "        self.stack = self.inputs\n",
    "        for layer in self.layers: self.stack = layer(self.stack)\n",
    "        self.loss  = c.losses.cross_entropy_with_softmax(self.stack, self.labels)\n",
    "        self.error = c.metrics.classification_error(self.stack, self.labels)\n",
    "    \n",
    "    def _build_trainer(self):\n",
    "        schedule     = c.learning_rate_schedule(self.LEARNING_RATE, c.UnitType.minibatch)\n",
    "        learner      = c.learners.sgd(self.stack.parameters, schedule)\n",
    "        printer      = c.logging.ProgressPrinter(tag='Training', num_epochs=self.EPOCH_COUNT)\n",
    "        self.trainer = c.Trainer(self.stack, (self.loss, self.error), learner, printer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
