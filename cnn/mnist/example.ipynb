{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: (70000, 1, 28, 28) labels: (70000, 10)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.datasets        import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing   import label_binarize\n",
    "\n",
    "PIXEL_RANGE = range(0, 255 + 1)\n",
    "IMAGE_RANGE = range(0, 9 + 1)\n",
    "\n",
    "def process(mnist):\n",
    "    # Process dataset to return features and labels for CNN\n",
    "    def features():\n",
    "        # Transform features to be float32 sets of 1x28x28 \n",
    "        # tensors with normalized pixel values.\n",
    "        return np.divide(\n",
    "            mnist.data, PIXEL_RANGE[-1]\n",
    "        ).astype(np.float32).reshape((-1, 1, 28, 28))\n",
    "    def labels():\n",
    "        # Transform labels to be float32 sets of 1x10\n",
    "        # tensors that are one-hot encoded.\n",
    "        return label_binarize(\n",
    "            mnist.target, classes=IMAGE_RANGE\n",
    "        ).astype(np.float32).reshape((-1, 10))\n",
    "    return features(), labels()\n",
    "\n",
    "\n",
    "# Download the MNIST dataset\n",
    "mnist            = fetch_mldata('MNIST original', data_home='.')\n",
    "features, labels = process(mnist)\n",
    "\n",
    "# Split train and test data\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)\n",
    "\n",
    "# Display feature and label shapes\n",
    "print('features:', features.shape, 'labels:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CNTK 2.0 CPU'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import CNTK\n",
    "import cntk as c\n",
    "\n",
    "# Display CNTK version\n",
    "' '.join([\n",
    "    c.__name__.upper(),\n",
    "    c.__version__,\n",
    "    str(c.device.all_devices()[0])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvNet():\n",
    "    IMAGE_SHAPE         = (1, 28, 28)\n",
    "    IMAGE_CLASSES       = [n for n in IMAGE_RANGE]\n",
    "    IMAGE_CLASS_COUNT   = len(IMAGE_CLASSES)\n",
    "    LEARNING_RATE       = [0.2] * 20 + [0.1] * 20 + [0.0001] * 20 + [0.00001] * 20\n",
    "    DEFAULT_EPOCH_COUNT = 80\n",
    "    DEFAULT_BATCH_SIZE  = 512\n",
    "    \n",
    "    def __init__(self, epoch_count=DEFAULT_EPOCH_COUNT, batch_size=DEFAULT_BATCH_SIZE):\n",
    "        self.epoch_count = epoch_count\n",
    "        self.batch_size  = batch_size\n",
    "        self._build()\n",
    "    \n",
    "    def evaluate(self, fn, feeds):\n",
    "        for epoch in range(self.epoch_count):\n",
    "            batch = self.batch(epoch, feeds)\n",
    "            fn(epoch, batch)\n",
    "    \n",
    "    def train(self, data):\n",
    "        self.trainer.train_minibatch(data)\n",
    "    \n",
    "    def test(self, data):\n",
    "        self.trainer.test_minibatch(data)\n",
    "    \n",
    "    def log_progress(self):\n",
    "        self.trainer.summarize_training_progress()\n",
    "    \n",
    "    def log_parameters(self):\n",
    "        c.logging.log_number_of_parameters(self.stack)\n",
    "        print()\n",
    "    \n",
    "    def save(self, version):\n",
    "        self.stack.save(self._to_file(version))\n",
    "    \n",
    "    def restore(self, version):\n",
    "        self.stack.restore(self._to_file(version))\n",
    "    \n",
    "    def batch(self, epoch, data):\n",
    "        def chunk(data):\n",
    "            slice_begin = epoch * self.batch_size\n",
    "            slice_end   = slice_begin + self.batch_size\n",
    "            return data[slice_begin:slice_end]\n",
    "        return {key: chunk(value) for key, value in data.items()}\n",
    "    \n",
    "    def _to_file(self, name):\n",
    "        file_names = [\n",
    "            self.__class__.__name__, 'MNIST', '{}.dnn'.format(name)\n",
    "        ]\n",
    "        return os.path.join(\n",
    "            '.', 'checkpoints', '_'.join(file_names)\n",
    "        )\n",
    "    \n",
    "    def _build(self):\n",
    "        self._build_inputs()\n",
    "        self._build_layers()\n",
    "        self._build_stack()\n",
    "        self._build_trainer()\n",
    "    \n",
    "    def _build_inputs(self):\n",
    "        self.features = c.input_variable(self.IMAGE_SHAPE,       np.float32, name='features')\n",
    "        self.labels   = c.input_variable(self.IMAGE_CLASS_COUNT, np.float32, name='labels')\n",
    "    \n",
    "    def _build_layers(self):\n",
    "        with c.layers.default_options(activation=c.ops.relu, pad=False):\n",
    "            self.layers  = [\n",
    "                c.layers.Convolution2D((5,5), 32, pad=True),\n",
    "                c.layers.MaxPooling((3,3), (2,2)),\n",
    "                c.layers.Convolution2D((3,3), 48),\n",
    "                c.layers.MaxPooling((3,3), (2,2)),\n",
    "                c.layers.Convolution2D((3,3), 64),\n",
    "                c.layers.Dense(96),\n",
    "                c.layers.Dropout(0.8),\n",
    "                c.layers.Dense(self.IMAGE_CLASS_COUNT, activation=None)\n",
    "            ]\n",
    "    \n",
    "    def _build_stack(self):\n",
    "        self.stack = self.features\n",
    "        for layer in self.layers: self.stack = layer(self.stack)\n",
    "        self.loss  = c.losses.cross_entropy_with_softmax(self.stack, self.labels)\n",
    "        self.error = c.metrics.classification_error(self.stack, self.labels)\n",
    "    \n",
    "    def _build_trainer(self):\n",
    "        schedule     = c.learning_rate_schedule(self.LEARNING_RATE, c.UnitType.minibatch)\n",
    "        learner      = c.learners.sgd(self.stack.parameters, schedule)\n",
    "        printer      = c.logging.ProgressPrinter(tag='Training', num_epochs=self.epoch_count)\n",
    "        self.trainer = c.Trainer(self.stack, (self.loss, self.error), learner, printer)\n",
    "    \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, type, value, traceback):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 98778 parameters in 10 parameter tensors.\n",
      "\n",
      "Learning rate per minibatch: 0.2\n",
      "Finished Epoch[1 of 80]: [Training] loss = 2.338234 * 512, metric = 88.28% * 512 1.585s (323.0 samples/s);\n",
      "Finished Epoch[2 of 80]: [Training] loss = 2.317653 * 512, metric = 90.23% * 512 0.932s (549.4 samples/s);\n",
      "Finished Epoch[3 of 80]: [Training] loss = 2.304480 * 512, metric = 88.87% * 512 0.925s (553.5 samples/s);\n",
      "Finished Epoch[4 of 80]: [Training] loss = 2.288018 * 512, metric = 86.72% * 512 0.971s (527.3 samples/s);\n",
      "Finished Epoch[5 of 80]: [Training] loss = 2.265363 * 512, metric = 83.79% * 512 0.927s (552.3 samples/s);\n",
      "Finished Epoch[6 of 80]: [Training] loss = 2.282706 * 512, metric = 87.70% * 512 0.905s (565.7 samples/s);\n",
      "Finished Epoch[7 of 80]: [Training] loss = 2.268359 * 512, metric = 84.57% * 512 1.314s (389.6 samples/s);\n",
      "Finished Epoch[8 of 80]: [Training] loss = 2.259836 * 512, metric = 86.33% * 512 0.997s (513.5 samples/s);\n",
      "Finished Epoch[9 of 80]: [Training] loss = 2.255026 * 512, metric = 82.62% * 512 0.949s (539.5 samples/s);\n",
      "Finished Epoch[10 of 80]: [Training] loss = 2.224123 * 512, metric = 81.25% * 512 0.918s (557.7 samples/s);\n",
      "Finished Epoch[11 of 80]: [Training] loss = 2.219965 * 512, metric = 81.25% * 512 0.925s (553.5 samples/s);\n",
      "Finished Epoch[12 of 80]: [Training] loss = 2.194169 * 512, metric = 80.86% * 512 0.946s (541.2 samples/s);\n",
      "Finished Epoch[13 of 80]: [Training] loss = 2.176867 * 512, metric = 79.10% * 512 0.912s (561.4 samples/s);\n",
      "Finished Epoch[14 of 80]: [Training] loss = 2.210103 * 512, metric = 82.42% * 512 0.903s (567.0 samples/s);\n",
      "Finished Epoch[15 of 80]: [Training] loss = 2.157077 * 512, metric = 77.15% * 512 0.897s (570.8 samples/s);\n",
      "Finished Epoch[16 of 80]: [Training] loss = 2.134295 * 512, metric = 74.61% * 512 0.927s (552.3 samples/s);\n",
      "Finished Epoch[17 of 80]: [Training] loss = 2.119318 * 512, metric = 77.73% * 512 0.912s (561.4 samples/s);\n",
      "Finished Epoch[18 of 80]: [Training] loss = 2.142354 * 512, metric = 77.54% * 512 0.907s (564.5 samples/s);\n",
      "Finished Epoch[19 of 80]: [Training] loss = 2.086344 * 512, metric = 72.07% * 512 0.910s (562.6 samples/s);\n",
      "Finished Epoch[20 of 80]: [Training] loss = 2.050606 * 512, metric = 71.88% * 512 0.953s (537.3 samples/s);\n",
      "Finished Epoch[21 of 80]: [Training] loss = 2.003901 * 512, metric = 71.68% * 512 0.909s (563.3 samples/s);\n",
      "Finished Epoch[22 of 80]: [Training] loss = 1.973091 * 512, metric = 67.19% * 512 0.920s (556.5 samples/s);\n",
      "Finished Epoch[23 of 80]: [Training] loss = 2.306735 * 512, metric = 81.25% * 512 1.158s (442.1 samples/s);\n",
      "Finished Epoch[24 of 80]: [Training] loss = 2.042721 * 512, metric = 66.60% * 512 1.006s (508.9 samples/s);\n",
      "Finished Epoch[25 of 80]: [Training] loss = 1.933018 * 512, metric = 65.23% * 512 0.930s (550.5 samples/s);\n",
      "Finished Epoch[26 of 80]: [Training] loss = 1.909312 * 512, metric = 67.58% * 512 0.924s (554.1 samples/s);\n",
      "Finished Epoch[27 of 80]: [Training] loss = 2.341585 * 512, metric = 80.27% * 512 0.903s (567.0 samples/s);\n",
      "Finished Epoch[28 of 80]: [Training] loss = 2.102844 * 512, metric = 71.68% * 512 0.948s (540.1 samples/s);\n",
      "Finished Epoch[29 of 80]: [Training] loss = 1.946763 * 512, metric = 62.89% * 512 0.903s (567.0 samples/s);\n",
      "Finished Epoch[30 of 80]: [Training] loss = 1.824914 * 512, metric = 62.50% * 512 0.914s (560.2 samples/s);\n",
      "Finished Epoch[31 of 80]: [Training] loss = 1.705979 * 512, metric = 59.38% * 512 0.903s (567.0 samples/s);\n",
      "Finished Epoch[32 of 80]: [Training] loss = 1.681012 * 512, metric = 59.77% * 512 0.924s (554.1 samples/s);\n",
      "Finished Epoch[33 of 80]: [Training] loss = 1.720618 * 512, metric = 60.55% * 512 0.908s (563.9 samples/s);\n",
      "Finished Epoch[34 of 80]: [Training] loss = 1.721586 * 512, metric = 59.96% * 512 0.929s (551.1 samples/s);\n",
      "Finished Epoch[35 of 80]: [Training] loss = 1.597906 * 512, metric = 51.95% * 512 0.902s (567.6 samples/s);\n",
      "Finished Epoch[36 of 80]: [Training] loss = 1.496598 * 512, metric = 50.59% * 512 0.918s (557.7 samples/s);\n",
      "Finished Epoch[37 of 80]: [Training] loss = 1.541594 * 512, metric = 51.17% * 512 0.925s (553.5 samples/s);\n",
      "Finished Epoch[38 of 80]: [Training] loss = 1.625750 * 512, metric = 57.23% * 512 0.921s (555.9 samples/s);\n",
      "Finished Epoch[39 of 80]: [Training] loss = 1.594201 * 512, metric = 57.23% * 512 1.179s (434.3 samples/s);\n",
      "Finished Epoch[40 of 80]: [Training] loss = 1.596182 * 512, metric = 56.45% * 512 0.951s (538.4 samples/s);\n",
      "Finished Epoch[41 of 80]: [Training] loss = 1.452538 * 512, metric = 50.39% * 512 0.966s (530.0 samples/s);\n",
      "Finished Epoch[42 of 80]: [Training] loss = 1.394735 * 512, metric = 46.48% * 512 0.929s (551.1 samples/s);\n",
      "Finished Epoch[43 of 80]: [Training] loss = 1.283889 * 512, metric = 44.53% * 512 0.914s (560.2 samples/s);\n",
      "Finished Epoch[44 of 80]: [Training] loss = 1.263268 * 512, metric = 44.53% * 512 0.947s (540.7 samples/s);\n",
      "Finished Epoch[45 of 80]: [Training] loss = 1.341830 * 512, metric = 45.70% * 512 0.927s (552.3 samples/s);\n",
      "Finished Epoch[46 of 80]: [Training] loss = 1.391926 * 512, metric = 48.05% * 512 0.904s (566.4 samples/s);\n",
      "Finished Epoch[47 of 80]: [Training] loss = 1.227893 * 512, metric = 42.58% * 512 0.951s (538.4 samples/s);\n",
      "Finished Epoch[48 of 80]: [Training] loss = 1.226778 * 512, metric = 42.19% * 512 0.921s (555.9 samples/s);\n",
      "Finished Epoch[49 of 80]: [Training] loss = 1.228241 * 512, metric = 41.02% * 512 0.958s (534.4 samples/s);\n",
      "Finished Epoch[50 of 80]: [Training] loss = 1.236513 * 512, metric = 42.97% * 512 0.904s (566.4 samples/s);\n",
      "Finished Epoch[51 of 80]: [Training] loss = 1.160173 * 512, metric = 42.38% * 512 0.900s (568.9 samples/s);\n",
      "Finished Epoch[52 of 80]: [Training] loss = 1.168792 * 512, metric = 40.62% * 512 0.907s (564.5 samples/s);\n",
      "Finished Epoch[53 of 80]: [Training] loss = 1.101371 * 512, metric = 38.67% * 512 0.978s (523.5 samples/s);\n",
      "Finished Epoch[54 of 80]: [Training] loss = 1.026618 * 512, metric = 32.42% * 512 0.933s (548.8 samples/s);\n",
      "Finished Epoch[55 of 80]: [Training] loss = 0.968230 * 512, metric = 31.84% * 512 1.148s (446.0 samples/s);\n",
      "Finished Epoch[56 of 80]: [Training] loss = 1.034976 * 512, metric = 33.98% * 512 0.972s (526.7 samples/s);\n",
      "Finished Epoch[57 of 80]: [Training] loss = 1.137153 * 512, metric = 37.50% * 512 0.933s (548.8 samples/s);\n",
      "Finished Epoch[58 of 80]: [Training] loss = 1.496185 * 512, metric = 48.44% * 512 0.900s (568.9 samples/s);\n",
      "Finished Epoch[59 of 80]: [Training] loss = 1.400913 * 512, metric = 46.48% * 512 0.901s (568.3 samples/s);\n",
      "Finished Epoch[60 of 80]: [Training] loss = 1.149972 * 512, metric = 36.33% * 512 0.927s (552.3 samples/s);\n",
      "Finished Epoch[61 of 80]: [Training] loss = 0.969470 * 512, metric = 31.84% * 512 0.901s (568.3 samples/s);\n",
      "Finished Epoch[62 of 80]: [Training] loss = 0.889342 * 512, metric = 30.86% * 512 0.899s (569.5 samples/s);\n",
      "Finished Epoch[63 of 80]: [Training] loss = 0.882104 * 512, metric = 29.10% * 512 0.907s (564.5 samples/s);\n",
      "Finished Epoch[64 of 80]: [Training] loss = 1.018214 * 512, metric = 33.79% * 512 0.913s (560.8 samples/s);\n",
      "Finished Epoch[65 of 80]: [Training] loss = 0.936621 * 512, metric = 30.47% * 512 1.036s (494.2 samples/s);\n",
      "Finished Epoch[66 of 80]: [Training] loss = 0.848761 * 512, metric = 27.15% * 512 1.070s (478.5 samples/s);\n",
      "Finished Epoch[67 of 80]: [Training] loss = 0.750204 * 512, metric = 23.44% * 512 1.037s (493.7 samples/s);\n",
      "Finished Epoch[68 of 80]: [Training] loss = 0.865778 * 512, metric = 27.34% * 512 0.980s (522.4 samples/s);\n",
      "Finished Epoch[69 of 80]: [Training] loss = 0.946592 * 512, metric = 32.81% * 512 0.989s (517.7 samples/s);\n",
      "Finished Epoch[70 of 80]: [Training] loss = 1.108201 * 512, metric = 39.45% * 512 1.092s (468.9 samples/s);\n",
      "Finished Epoch[71 of 80]: [Training] loss = 0.902563 * 512, metric = 27.34% * 512 1.087s (471.0 samples/s);\n",
      "Finished Epoch[72 of 80]: [Training] loss = 0.924549 * 512, metric = 31.05% * 512 1.119s (457.6 samples/s);\n",
      "Finished Epoch[73 of 80]: [Training] loss = 0.876559 * 512, metric = 29.88% * 512 0.970s (527.8 samples/s);\n",
      "Finished Epoch[74 of 80]: [Training] loss = 0.830228 * 512, metric = 25.78% * 512 0.996s (514.1 samples/s);\n",
      "Finished Epoch[75 of 80]: [Training] loss = 0.756051 * 512, metric = 25.39% * 512 1.043s (490.9 samples/s);\n",
      "Finished Epoch[76 of 80]: [Training] loss = 0.739997 * 512, metric = 24.02% * 512 0.955s (536.1 samples/s);\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch[77 of 80]: [Training] loss = 0.663016 * 512, metric = 22.07% * 512 0.947s (540.7 samples/s);\n",
      "Finished Epoch[78 of 80]: [Training] loss = 0.661281 * 512, metric = 23.63% * 512 0.919s (557.1 samples/s);\n",
      "Finished Epoch[79 of 80]: [Training] loss = 0.680322 * 512, metric = 22.66% * 512 0.901s (568.3 samples/s);\n",
      "Finished Epoch[80 of 80]: [Training] loss = 0.684739 * 512, metric = 21.68% * 512 0.904s (566.4 samples/s);\n"
     ]
    }
   ],
   "source": [
    "with ConvNet() as cnn:\n",
    "    def train(epoch, batch_map):\n",
    "        cnn.train(batch_map)\n",
    "        cnn.log_progress()\n",
    "    cnn.log_parameters()\n",
    "    cnn.evaluate(train, {'features': train_features, 'labels': train_labels})\n",
    "    cnn.save('train')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
